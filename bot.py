import telebot
import numpy as np
import librosa
import subprocess
import os
from tensorflow.keras.models import load_model

# üîê –¢–æ–∫–µ–Ω –±–æ—Ç–∞
TOKEN = "7424010381:AAFhJOwnBKclkx4WVs6cG1btN_vnSK1tLVk"
bot = telebot.TeleBot(TOKEN)

# üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = load_model("speaker_classifier.keras")

# üè∑Ô∏è –ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
labels = {
    0: "–ê–Ω–Ω–∞",
    1: "–ë–∞–±—É—à–∫–∞",
    2: "–í–ª–∞–¥",
    3: "–î–µ–¥—É—à–∫–∞",
    4: "–ù–∏–∫–∏—Ç–∞"
}

# üí¨ –û—Ç–≤–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç
@bot.message_handler(content_types=['text'])
def handle_text(message):
    bot.reply_to(message, "üëã –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª (WAV, MP3, OGG), –∏ —è —Å–∫–∞–∂—É, –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç.")

# üéß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –∏ voice
@bot.message_handler(content_types=['audio', 'document', 'voice'])
def handle_audio(message):
    try:
        # üì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if message.voice:
            file_info = bot.get_file(message.voice.file_id)
            ext = ".ogg"
        elif message.audio:
            file_info = bot.get_file(message.audio.file_id)
            ext = os.path.splitext(file_info.file_path)[1]
        elif message.document:
            file_info = bot.get_file(message.document.file_id)
            ext = os.path.splitext(file_info.file_path)[1]
        else:
            bot.reply_to(message, "‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")
            return

        file_data = bot.download_file(file_info.file_path)
        input_file = f"input{ext}"
        with open(input_file, "wb") as f:
            f.write(file_data)

        # üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        wav_file = "converted.wav"
        if ext.lower() != ".wav":
            subprocess.run(['ffmpeg', '-y', '-i', input_file, wav_file], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        else:
            wav_file = input_file

        # üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ MFCC
        y, sr = librosa.load(wav_file, sr=16000)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T

        max_len = model.input_shape[1]
        if mfcc.shape[0] > max_len:
            mfcc = mfcc[:max_len]
        else:
            mfcc = np.pad(mfcc, ((0, max_len - mfcc.shape[0]), (0, 0)))

        mfcc = np.expand_dims(mfcc, axis=0)

        # ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred = model.predict(mfcc)
        confidence = np.max(pred)
        predicted = np.argmax(pred)

        if confidence < 0.3:
            bot.reply_to(message, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.")
        else:
            bot.reply_to(message, f"üó£Ô∏è –ì–æ–≤–æ—Ä—è—â–∏–π: {labels[predicted]}")

        # üßπ –û—á–∏—Å—Ç–∫–∞
        for f in [input_file, "converted.wav"]:
            if os.path.exists(f):
                os.remove(f)

    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")

# ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
bot.remove_webhook()
bot.polling()
