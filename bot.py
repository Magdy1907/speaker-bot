import telebot
import numpy as np
import librosa
import subprocess
from tensorflow.keras.models import load_model
import threading

# üîê –¢–æ–∫–µ–Ω Telegram-–±–æ—Ç–∞
TOKEN = "7424010381:AAF1_4x5XJpUj7V_d0KgmbZynggT7bJqxvg"
bot = telebot.TeleBot(TOKEN)

# üß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = load_model("speaker_classifier.keras")

# üè∑Ô∏è –ö–ª–∞—Å—Å—ã
labels = {0: "speaker1", 1: "speaker2", 2: "speaker3"}

def process_audio(file_info, message):
    try:
        downloaded_file = bot.download_file(file_info.file_path)
        with open("input.ogg", 'wb') as f:
            f.write(downloaded_file)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ wav
        subprocess.call(['ffmpeg', '-y', '-i', 'input.ogg', 'input.wav'])

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ MFCC
        y, sr = librosa.load("input.wav", sr=16000)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T
        mfcc = mfcc[:348] if mfcc.shape[0] > 348 else np.pad(mfcc, ((0, 348 - mfcc.shape[0]), (0, 0)))
        mfcc = np.expand_dims(mfcc, axis=0)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred = model.predict(mfcc)
        speaker = labels[np.argmax(pred)]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –º–µ–Ω–µ–µ 60% —Ç–æ—á–Ω–æ—Å—Ç–∏)
        confidence = np.max(pred)
        if confidence < 0.6:
            bot.reply_to(message, "‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.")
        else:
            bot.reply_to(message, f"üîä –ì–æ–≤–æ—Ä—è—â–∏–π: {speaker}")

    except Exception as e:
        bot.reply_to(message, f"‚ùå –û—à–∏–±–∫–∞: {e}")

@bot.message_handler(content_types=['voice'])
def handle_voice(message):
    file_info = bot.get_file(message.voice.file_id)

    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
    thread = threading.Thread(target=process_audio, args=(file_info, message))
    thread.start()

# –ó–∞–ø—É—Å–∫
bot.polling()
