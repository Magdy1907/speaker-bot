import telebot
import numpy as np
import librosa
import subprocess
import os
from tensorflow.keras.models import load_model

# üîê –¢–æ–∫–µ–Ω Telegram-–±–æ—Ç–∞
TOKEN = "7424010381:AAF1_4x5XJpUj7V_d0KgmbZynggT7bJqxvg"
bot = telebot.TeleBot(TOKEN)

# üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model = load_model("speaker_classifier.keras")

# üè∑Ô∏è –°–ª–æ–≤–∞—Ä—å –∫–ª–∞—Å—Å–æ–≤ (–∏–º–µ–Ω–∞ –≥–æ–≤–æ—Ä—è—â–∏—Ö)
labels = {
    0: "–ê–Ω–Ω–∞",
    1: "–ë–∞–±—É—à–∫–∞",
    2: "–í–ª–∞–¥",
    3: "–î–µ–¥—É—à–∫–∞",
    4: "–ù–∏–∫–∏—Ç–∞"
}

# üí¨ –û—Ç–≤–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
@bot.message_handler(content_types=['text'])
def handle_text(message):
    bot.reply_to(
        message,
        "üëã –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª (WAV, OGG, MP3), –∏ —è —Å–∫–∞–∂—É, –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç."
    )

# üéß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
@bot.message_handler(content_types=['audio', 'document'])
def handle_audio(message):
    try:
        # üì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        file_info = bot.get_file(message.audio.file_id if message.audio else message.document.file_id)
        downloaded_file = bot.download_file(file_info.file_path)

        # üìù –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        ext = os.path.splitext(file_info.file_path)[1]
        input_filename = f"input{ext}"
        with open(input_filename, 'wb') as f:
            f.write(downloaded_file)

        # üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if ext.lower() != '.wav':
            subprocess.call(['ffmpeg', '-y', '-i', input_filename, 'converted.wav'])
            input_path = 'converted.wav'
        else:
            input_path = input_filename

        # üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ MFCC
        y, sr = librosa.load(input_path, sr=16000)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T

        # üìè –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω–µ
        max_len = model.input_shape[1]
        if mfcc.shape[0] > max_len:
            mfcc = mfcc[:max_len]
        else:
            mfcc = np.pad(mfcc, ((0, max_len - mfcc.shape[0]), (0, 0)))

        mfcc = np.expand_dims(mfcc, axis=0)

        # üîç –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred = model.predict(mfcc)
        max_prob = np.max(pred)
        pred_class = np.argmax(pred)

        if max_prob < 0.7:
            bot.reply_to(message, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")
        else:
            bot.reply_to(message, f"üó£Ô∏è –ì–æ–≤–æ—Ä—è—â–∏–π: {labels[pred_class]} (–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {max_prob:.2f})")

        # üßπ –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        os.remove(input_filename)
        if os.path.exists("converted.wav"):
            os.remove("converted.wav")

    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")

# üö´ –£–¥–∞–ª—è–µ–º –≤–µ–±—Ö—É–∫ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
bot.remove_webhook()

# ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
bot.polling()
