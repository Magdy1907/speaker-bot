import telebot
import numpy as np
import librosa
import subprocess
import os
from tensorflow.keras.models import load_model

# üîê –¢–æ–∫–µ–Ω Telegram-–±–æ—Ç–∞
TOKEN = "7424010381:AAF1_4x5XJpUj7V_d0KgmbZynggT7bJqxvg"  # 
bot = telebot.TeleBot(TOKEN)

# üß† –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model = load_model("speaker_classifier.keras")

# üè∑Ô∏è –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–æ–∫
labels = {0: "speaker1", 1: "speaker2", 2: "speaker3"}

# üí¨ –û—Ç–≤–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
@bot.message_handler(content_types=['text'])
def handle_text(message):
    bot.reply_to(
        message,
        "üëã –ü—Ä–∏–≤–µ—Ç! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª (WAV, MP3, OGG –∏ —Ç.–¥.), —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–æ–≤–æ—Ä—è—â–µ–≥–æ."
    )

# üéß –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
@bot.message_handler(content_types=['audio', 'document'])
def handle_audio(message):
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        file_info = bot.get_file(message.audio.file_id if message.audio else message.document.file_id)
        downloaded_file = bot.download_file(file_info.file_path)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        original_extension = os.path.splitext(file_info.file_path)[1]
        input_filename = f"input{original_extension}"
        with open(input_filename, 'wb') as f:
            f.write(downloaded_file)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if original_extension.lower() != '.wav':
            subprocess.call(['ffmpeg', '-y', '-i', input_filename, 'converted.wav'])
            input_path = 'converted.wav'
        else:
            input_path = input_filename

        # –ò–∑–≤–ª–µ–∫–∞–µ–º MFCC-–ø—Ä–∏–∑–Ω–∞–∫–∏
        y, sr = librosa.load(input_path, sr=16000)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T
        mfcc = mfcc[:348] if mfcc.shape[0] > 348 else np.pad(mfcc, ((0, 348 - mfcc.shape[0]), (0, 0)))
        mfcc = np.expand_dims(mfcc, axis=0)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred = model.predict(mfcc)
        speaker = labels[np.argmax(pred)]
        bot.reply_to(message, f"üîä –ì–æ–≤–æ—Ä—è—â–∏–π: {speaker}")

        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        os.remove(input_filename)
        if os.path.exists("converted.wav"):
            os.remove("converted.wav")

    except Exception as e:
        bot.reply_to(message, f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

# ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
bot.polling()
