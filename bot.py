import telebot
import numpy as np
import librosa
import subprocess
import os
from tensorflow.keras.models import load_model

# üîê –¢–æ–∫–µ–Ω Telegram-–±–æ—Ç–∞
TOKEN = "7424010381:AAF1_4x5XJpUj7V_d0KgmbZynggT7bJqxvg"
bot = telebot.TeleBot(TOKEN)

# üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = load_model("speaker_classifier.keras")

# üè∑Ô∏è –ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
labels = {
    0: "–ê–Ω–Ω–∞",
    1: "–ë–∞–±—É—à–∫–∞",
    2: "–í–ª–∞–¥",
    3: "–î–µ–¥—É—à–∫–∞",
    4: "–ù–∏–∫–∏—Ç–∞"
}

# üí¨ –û—Ç–≤–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
@bot.message_handler(content_types=['text'])
def handle_text(message):
    bot.reply_to(message, "üëã –ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª (WAV, OGG, MP3) –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è —Å–∫–∞–∂—É, –∫—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç.")

# üéß –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∞—É–¥–∏–æ (–≤–∫–ª—é—á–∞—è voice)
@bot.message_handler(content_types=['audio', 'document', 'voice'])
def handle_audio(message):
    try:
        # üì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if message.voice:
            file_info = bot.get_file(message.voice.file_id)
            original_extension = ".ogg"
        elif message.audio:
            file_info = bot.get_file(message.audio.file_id)
            original_extension = os.path.splitext(file_info.file_path)[1]
        elif message.document:
            file_info = bot.get_file(message.document.file_id)
            original_extension = os.path.splitext(file_info.file_path)[1]
        else:
            bot.reply_to(message, "‚ö†Ô∏è –¢–∏–ø —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")
            return

        downloaded_file = bot.download_file(file_info.file_path)
        input_filename = f"input{original_extension}"

        with open(input_filename, 'wb') as f:
            f.write(downloaded_file)

        # üéµ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        if original_extension.lower() != '.wav':
            subprocess.call(['ffmpeg', '-y', '-i', input_filename, 'converted.wav'])
            input_path = 'converted.wav'
        else:
            input_path = input_filename

        # üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ MFCC
        y, sr = librosa.load(input_path, sr=16000)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T

        max_len = model.input_shape[1]
        if mfcc.shape[0] > max_len:
            mfcc = mfcc[:max_len]
        else:
            mfcc = np.pad(mfcc, ((0, max_len - mfcc.shape[0]), (0, 0)))

        mfcc = np.expand_dims(mfcc, axis=0)

        # ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        pred = model.predict(mfcc)
        max_prob = np.max(pred)
        pred_class = np.argmax(pred)

        if max_prob < 0.5:
            bot.reply_to(message, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.")
        else:
            bot.reply_to(message, f"üó£Ô∏è –ì–æ–≤–æ—Ä—è—â–∏–π: {labels[pred_class]}")

        # üßπ –û—á–∏—Å—Ç–∫–∞
        os.remove(input_filename)
        if os.path.exists("converted.wav"):
            os.remove("converted.wav")

    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

# üöÄ –°—Ç–∞—Ä—Ç –±–æ—Ç–∞
bot.remove_webhook()
bot.polling()
